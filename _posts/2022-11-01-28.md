---

title: 肝s了
categories:
- multi-model
feature_image: "![image](https://user-images.githubusercontent.com/53364734/199033801-4709db0d-6c53-44f7-b3c5-83e4003bc6b2.png)
"

---
自己模型的第一次生成紀念：

['\<EOC\>', '\<EOC\>', '\<EOC\>', '\<EOC\>', '\<EOC\>', '\<EOC\>', '\<EOC\>', '\<EOC\>', '\<EOC\>', '\<EOC\>']
 
与视觉问答相比，视觉对话不仅要求agent能够参与到一个关于图像的问题中，而且要求agent能够充分利用之前提问和回答的线索。因此，答题者、问题、对话记录和图像之间的互动是产生正确答案的关键

搞一下：[https://github.com/CPJKU/EfficientLEAF](https://github.com/CPJKU/EfficientLEAF)，可以移植到torch上。

不要闭门造车，多读论文。好不好
<!-- more -->
  
更改链接：[![更改博客链接](https://user-images.githubusercontent.com/53364734/192180297-c1654533-eb5f-4bf9-aa9f-ab830208a5e3.png)](https://github.com/lizeyujack/lizeyujack.github.io/edit/main/_posts/2022-11-01-28.md)
  
ICME2022 trackes:

![image](https://user-images.githubusercontent.com/53364734/199026981-51c6e2d6-1556-4754-9ee3-2f79d8750e45.png)
  
- gpt2的vocab：
[https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json](https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json)

这些天撸代码，其实收货挺多的(工程上)，但是结果还是没有出来。没有意思。
揪其原因来讲，还是没有找到真正痛的点。没有idea。
虽然有的时候，可以通过碰运气来试出来好的结果。但是我觉得哪样的效率不搞，而且成功的概率也很低。
我主要是没有沉淀出来对应的模型。如果可以直接跑出来。我觉得应该努力争取一下，多读一些vd相关的论文。正如学长灵魂的拷问，为什么不做主流的，而做一个小众的？
还有一个比较致命的伤，就是没有卡。现在模型有的，数据处理好的。但是卡还不能继续跑。(wuyu)

好不好搞？？
![image](https://user-images.githubusercontent.com/53364734/199510183-8d86cdc0-e7ec-41d0-882e-60025541dabb.png)



