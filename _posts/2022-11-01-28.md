---

title: 肝s了
categories:
- multi-model
feature_image: "![image](https://user-images.githubusercontent.com/53364734/199033801-4709db0d-6c53-44f7-b3c5-83e4003bc6b2.png)
"

---
自己模型的第一次生成紀念：

['<EOC>', '<EOC>', '<EOC>', '<EOC>', '<EOC>', '<EOC>', '<EOC>', '<EOC>', '<EOC>', '<EOC>']
 
与视觉问答相比，视觉对话不仅要求agent能够参与到一个关于图像的问题中，而且要求agent能够充分利用之前提问和回答的线索。因此，答题者、问题、对话记录和图像之间的互动是产生正确答案的关键

<!-- more -->
  
更改链接：[![更改博客链接](https://user-images.githubusercontent.com/53364734/192180297-c1654533-eb5f-4bf9-aa9f-ab830208a5e3.png)](https://github.com/lizeyujack/lizeyujack.github.io/edit/main/_posts/2022-11-01-28.md)
  
ICME2022 trackes:

![image](https://user-images.githubusercontent.com/53364734/199026981-51c6e2d6-1556-4754-9ee3-2f79d8750e45.png)
  
- gpt2的vocab：
[https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json](https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json)

