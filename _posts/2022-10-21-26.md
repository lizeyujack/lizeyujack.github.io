---

title: 做不出来，提头来见
categories:
- multi-model generation
feature_image: "https://user-images.githubusercontent.com/53364734/192078882-190b1b14-a1ee-4590-ac1f-56ac81ffeb56.png"

---

心态稳，才是真的稳，稳则无敌~ 杰克李

[transformer torch](https://github.com/harvardnlp/annotated-transformer)版本 contributed by Harvard University

恭喜室友找到实习！Envy you but not a bit jealous!
<!-- more -->


[Position Encoding](https://blog.csdn.net/qq_43613342/article/details/109675678#:~:text=Position%20Embedding%E6%9C%80%E5%85%88%E5%9C%A8%E3%80%8AAttention%20Is%20All%20You%20Need%E3%80%8B%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E4%B8%AD%E6%8F%90%E5%87%BA%EF%BC%8CPosition,Embedding%E5%8A%A0%E5%9C%A8%E8%AF%8D%E5%90%91%E9%87%8F%E5%B1%82%E4%B9%8B%E5%90%8E%EF%BC%8C%E8%A1%A5%E5%85%85%E4%BD%8D%E7%BD%AE%E4%BF%A1%E6%81%AF%EF%BC%8C%E4%BE%8B%E5%A6%82%E4%B9%8B%E5%89%8D%E9%82%A3%E4%B8%AA%E4%BE%8B%E5%AD%90%E4%B8%AD%E6%88%91%E5%BE%97%E5%88%B0%E7%9A%84%E8%AF%8D%E5%90%91%E9%87%8F%E7%BC%96%E7%A0%81size%3Dtorch.Size%20%28%5B2%2C%204%2C%205%5D%29%2C%E7%8E%B0%E5%9C%A8%E6%88%91%E5%8A%A0%E5%85%A5%E4%BA%86%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%EF%BC%8C%E8%AE%BE%E7%BB%B4%E5%BA%A6%E4%B9%9F%E8%AE%BE%E4%B8%BA5%EF%BC%8C%E9%82%A3%E4%B9%88%E7%8E%B0%E5%9C%A8%E6%88%91%E4%BB%AC%E5%BE%97%E5%88%B0%E7%9A%84%E5%90%91%E9%87%8F%E5%B0%B1%E4%B8%BAtorch.Size%20%28%5B2%2C%204%2C%2010%5D%29%E3%80%82) source form CSDN


更改链接：[![更改博客链接](https://user-images.githubusercontent.com/53364734/192180297-c1654533-eb5f-4bf9-aa9f-ab830208a5e3.png)](https://github.com/lizeyujack/lizeyujack.github.io/edit/main/_posts/2022-10-21-26.md)

难得有卡，跑一个bert二分类 。tmd
![image](https://user-images.githubusercontent.com/53364734/197139976-a66ca316-fe54-4c00-84d2-16f681d6b60b.png)

Examples of inputs and outputs obtained from our **80B** parameter model,Flamingo
异常检测，如果不在文件夹，就下载。os.popen()可以用python执行bash指令。很方便；

问author一个问题：
![image](https://user-images.githubusercontent.com/53364734/197348256-41434abb-5bbf-413a-840c-75fd0b9c4fda.png)
chain of Thought: mumu警官
{% include video.html id="1t8411e7Ug" t="0" title="Siteleaf tutorial video" %}


输入：GPT风格的样式。[SEP]

input image:已处理好，等待输入【和dialog history对应】。
decoder也要单独处理，[u1,u2,u3,....]
缺失的图片，直接传None.
困难。如何衔接？如何正确回传参数。我建议在flamingo-mini上做出来。
学到了查看类属性的方法：`DataLoader.__dict__`

```python
{%raw%}
('I just got back from a family reunion.', 'okay[SEP]oh okay', None)
('I just got back from a family reunion.[CLS]okay[SEP]oh okay', 'It was fun.[SEP]It was held at a restaurant.', None)
('I just got back from a family reunion.[CLS]okay[SEP]oh okay[CLS]It was fun.[SEP]It was held at a restaurant.', 'what are you doing now[SEP]okay enjoy', None)
('I just got back from a family reunion.[CLS]okay[SEP]oh okay[CLS]It was fun.[SEP]It was held at a restaurant.[CLS]what are you doing now[SEP]okay enjoy', "I'm just relaxing.[SEP]I took some photos of the reunion.", None)
("I just got back from a family reunion.[CLS]okay[SEP]oh okay[CLS]It was fun.[SEP]It was held at a restaurant.[CLS]what are you doing now[SEP]okay enjoy[CLS]I'm just relaxing.[SEP]I took some photos of the reunion.", 'okay', None)
("I just got back from a family reunion.[CLS]okay[SEP]oh okay[CLS]It was fun.[SEP]It was held at a restaurant.[CLS]what are you doing now[SEP]okay enjoy[CLS]I'm just relaxing.[SEP]I took some photos of the reunion.[CLS]okay", 'oh', None)
("I just got back from a family reunion.[CLS]okay[SEP]oh okay[CLS]It was fun.[SEP]It was held at a restaurant.[CLS]what are you doing now[SEP]okay enjoy[CLS]I'm just relaxing.[SEP]I took some photos of the reunion.[CLS]okay[CLS]Here's one with my aunt Hallie.[SEP]The photo has your aunt Hallie. Objects in the photo: Woman, Wine glass, Clothing, Face[CLS]oh", None, ['The photo has your aunt Hallie. Objects in the photo: Woman, Wine glass, Clothing, Face', 'train/175798036bc27bfb', 'https://c4.staticflickr.com/5/4123/4791319436_99d6d6bf81_o.jpg'])

{%endraw%}
```


结构化思考能力： 布鲁克的《批判思维》
              麦肯锡的《金字塔原理》
自在不成人，成人不自在。

心灵受到挑战。yk
Don't u think it is carzy? ![image](https://user-images.githubusercontent.com/53364734/197945173-ff2cfc37-b2f1-4d1c-b6dd-5c109a3337b0.png)


Dataloader中如果需要变长，需要将序列换成对应的向量： 参考一下[S.O.](https://stackoverflow.com/questions/65279115/how-to-use-collate-fn-with-dataloaders)
开始 项目解释一下板子。
![Screenshot from 2022-10-25 14-57-55](https://user-images.githubusercontent.com/53364734/197944996-caea4621-eb58-4ef9-9b32-2ed55053801f.png)

---

```python
{%raw%}
# -*- encoding: utf-8 -*-
'''
@File    :   utils.py
@Date    :   10-28-2022
@Time    :   00:30:13
@Author  :   lizeyujack@sjtu.edu.cn 
'''
{%raw%}
def merge_img(img):
    '''
    @File    :   utils.py
    @Date    :   10-29-2022
    @Time    :   13:22:20
    @Author  :   lizeyujack@sjtu.edu.cn 
    '''
    batch_size = len([i for i in img])
    padded_img = torch.zeros((batch_size,1,3,224,224))
    for i,img in enumerate(img):
        if img is not None and torch.is_tensor(img):
            padded_img[i] = img
    print(padded_img)
    return padded_img

    return [i for i in img]

def merge_label(sequences):
    lengths = [seq.size()[1] for seq in sequences]
    max_len = 1 if max(lengths) == 0 else max(lengths)
    padded_seqs = torch.ones(len(sequences), max_len).long()
    
    for i, seq in enumerate(sequences):
        end = lengths[i]
        print('end\t',end)
        # print('end\t',end)
        print('seq',seq.shape)
        print('padded_seqs',padded_seqs.shape)
        padded_seqs[i,:end] = seq[:end]
    return padded_seqs, lengths
data.sort(key=lambda x: len(x['dialog_history_input']), reverse=True)
item_info = {}
for key in data[0].keys():
    item_info[key] = [d[key] for d in data]
print(item_info)
# print()
dialog_history_input, dialog_history_input_len = merge(item_info['dialog_history_input'],False)
print(dialog_history_input)
dialog_history_atten_mask,dialog_history_atten_mask_len = merge(item_info['dialog_history_atten_mask'],False)
response_input, response_input_len = merge_label(item_info['response_input'])
response_atten_masks, response_atten_masks_len = merge(item_info['response_atten_mask'],False)
share_images = merge_img(item_info['share_images'])

dialog_history_input = dialog_history_input.contiguous().cuda()
dialog_history_atten_mask = dialog_history_atten_mask.contiguous().cuda()
response_input = response_input.contiguous().cuda()
# share_images = share_images.contiguous().cuda()
data_info = {}
for k in item_info.keys():
    try:
        data_info[k] = locals()[k]
    except:
        data_info[k] = item_info[k]
data_info['dialog_history_input_len'] = dialog_history_input_len
data_info['dialog_history_atten_mask_len'] = dialog_history_atten_mask_len
data_info['response_input_len'] = response_input_len
data_info['response_atten_masks_len'] = response_atten_masks_len
# data_info['share_images_len'] = share_images_len

# print(data_info)
return data_info
{%endraw%}
```
